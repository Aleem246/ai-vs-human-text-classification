{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data download with kaggle api\n"
      ],
      "metadata": {
        "id": "xv-Tlnj-6pk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#upload kaggle.json file which is downloaded from the kaggle site for the api key and access\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "Bo9hlstU5zLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# giving permissions to download and unzip the dataset\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# download the dataset\n",
        "!kaggle datasets download -d dillonwongso/ai-generated-vs-human-text-cleaned"
      ],
      "metadata": {
        "id": "vjG8dYKSA7Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ai-generated-vs-human-text-cleaned.zip\n"
      ],
      "metadata": {
        "id": "oniRKUsj6fRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download The Libraries"
      ],
      "metadata": {
        "id": "b-jEHTE_7-wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing libraries needed\n",
        "!pip install transformers\n"
      ],
      "metadata": {
        "id": "NFqj-c6C7RC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model development"
      ],
      "metadata": {
        "id": "2SO9lGojd66B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import of libraries\n"
      ],
      "metadata": {
        "id": "o0D9L51h7F62"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrqHZWdhAGGy"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFBertForSequenceClassification, BertTokenizerFast\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### load dataset"
      ],
      "metadata": {
        "id": "JiCsdYRCdlC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv(\"preprocessed-50k.csv\")\n",
        "\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "fiuLnFcobt1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['source'] = data['source'].map({'human': 1, 'ai': 0})"
      ],
      "metadata": {
        "id": "RagxAsnFBJcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = data['text'].values\n",
        "labels = data['source'].values"
      ],
      "metadata": {
        "id": "CqsJ6rYRcN_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### initialize tokenizer"
      ],
      "metadata": {
        "id": "a3ktif47drXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
      ],
      "metadata": {
        "id": "SoXZuLoEsoAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def tokenize(texts, tokenizer, batch_size=10000, max_length=256):\n",
        "    n = len(texts)\n",
        "    print(f\"Total texts: {n}\")\n",
        "    all_input_ids = []\n",
        "    all_attention_masks = []\n",
        "\n",
        "    for i in range(0, n, batch_size):\n",
        "        print(f\"Processing batch {i // batch_size + 1}\")\n",
        "        batch = texts[i:i + batch_size]\n",
        "        batch_encoding = tokenizer(\n",
        "            list(batch),\n",
        "            max_length=max_length,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_tensors=\"tf\"\n",
        "        )\n",
        "        all_input_ids.append(batch_encoding['input_ids'])\n",
        "        all_attention_masks.append(batch_encoding['attention_mask'])\n",
        "\n",
        "    # Concatenate all batches into a single tensor\n",
        "    return {\n",
        "        \"input_ids\": tf.concat(all_input_ids, axis=0),\n",
        "        \"attention_mask\": tf.concat(all_attention_masks, axis=0)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "XtpQCUERccDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### splitting the data"
      ],
      "metadata": {
        "id": "3BOdhnRSeAn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "CgOax_4Nc0C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "id": "GdwsGKRvkyus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model development and compiling"
      ],
      "metadata": {
        "id": "EEEerRsReEUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenize(train_texts, tokenizer)\n",
        "test_encodings = tokenize(test_texts, tokenizer)\n"
      ],
      "metadata": {
        "id": "ikfWhhqAclhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = {key: value.numpy() for key, value in train_encodings.items()}\n",
        "print({key: len(value) for key, value in train_encodings.items()})\n"
      ],
      "metadata": {
        "id": "kQ-fGrRcCnF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    train_labels\n",
        ")).shuffle(len(train_labels)).batch(16)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_encodings),\n",
        "    test_labels\n",
        ")).batch(16)"
      ],
      "metadata": {
        "id": "49LDU5i4c9M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFBertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=2\n",
        ")\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "V4XiIutsdCkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model"
      ],
      "metadata": {
        "id": "Snd9qoc1eIks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=test_dataset,\n",
        "    epochs=4\n",
        ")"
      ],
      "metadata": {
        "id": "zXVkeTh9dGIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### predictions"
      ],
      "metadata": {
        "id": "LFXsgoOteLCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "7Ze8I__6dRKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_dataset).logits\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(classification_report(test_labels, predicted_classes))"
      ],
      "metadata": {
        "id": "sfvvOQDrdUR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### saving the model"
      ],
      "metadata": {
        "id": "gHsCQKMzeNW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"ai_human_classifier\")\n",
        "tokenizer.save_pretrained(\"ai_human_classifier\")"
      ],
      "metadata": {
        "id": "BZuVOT5JdXQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r ai_human_classifier.zip ai_human_classifier"
      ],
      "metadata": {
        "id": "5pkCBS9tyrze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"ai_human_classifier.zip\")"
      ],
      "metadata": {
        "id": "frGxdpzJy3yD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}